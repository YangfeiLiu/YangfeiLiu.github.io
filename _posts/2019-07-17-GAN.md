---
layout:     post
title:      "GAN"
subtitle:   "GAN学习中的体会记录"
date:       2019-07-17
author:     "柳阳飞"
tags:
        - GAN
        - pytorch keras tensorflow
        - image
---

###### 接触GAN的时候还是在大四做毕业设计的时候，由于当时是从通信工程学院转到了现在的人工智能学院，所以毕业设计就跟着这边的老师做了，当时老师布置的题目就是实现论文[*Semantic Segmentation using Adversarial Networks*](https://arxiv.org/pdf/1611.08408.pdf) 这是16年的一篇cvpr上的文章，也是首次将GAN运用在图像的语义分割上。这篇文章的实现难度对于当时还没有接触过深度学习和python的我来说简直就是不可能完成的任务，所以用一个月做完了论文的翻译工作(老师当时还给了另外三篇关于GAN和语义分割的文章)之后就赶紧去学习，到现在将近两年的时间也没有完全搞懂这篇文章的一些方法。

### GAN

#### 入门介绍

说起GAN，首先要提的一篇文章就是2014年*Ian J. Goodfellow* 的文章[*Generative Adversarial Nets*](https://arxiv.org/pdf/1406.2661.pdf)，这篇文章首次将GAN带入人们的视线，自此便火的一发不可收拾。

 Generative Adversarial Nets文章的摘要

![gan](E:\blogs\xidian-liuyangfei.github.io\img\20190717\gan_abstract.png)

这个摘要实际上已经把GAN介绍完了，就是两个网络相互博弈的framework，其中的一个网络成为生成网络(Generator)，另一个网络称为判别网络(Discriminator)。生成网络的目的就是从一个域(噪声或者其他数据)生成另一个域的数据，或者称为造假的过程，判别网络的目的就是区分输入进网络的数据来自哪里(生成的数据或真实的数据)，经过两个网络的对抗训练，最后得到一个能力很强的生成模型，这个模型可以用来生成数据，模拟数据分布，造假。

GAN模型参考这副图

![model](E:\blogs\xidian-liuyangfei.github.io\img\20190717\gan_model.png)

#### 损失函数

其实从GAN的优化目标中也可以很好的体会到GAN的原理
$$
\min_G\max_D=E_{x\sim p_{data}(x)}[\log D(x)]+E_{z\sim p_z(z)}[\log (1-D(G(z)))]
$$
